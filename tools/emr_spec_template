# Name of the cluster.
CLUSTER_NAME=${USER}-cluster

# Number of worker instances in the cluster.
NUM_INSTANCES=3

# The id of the ssh key that you want to use to connect to the cluster.
SSH_ID=lynx-cli

# The private key file for the ID above.
SSH_KEY=~/.ssh/lynx-cli.pem

# Which region to run in.
REGION=us-east-1

# Which instance type to create.
TYPE=m3.2xlarge
# These are determined by the instance type above. You still need to fill these. Sorry. :)
# See http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/TaskConfiguration_H2.html
# for memory limits and
# https://aws.amazon.com/ec2/instance-types/
# for number of cores.
CORES=8
USE_RAM_GB=19 # yarn limit minus 1GB so that the application master fits somewhere
# A local path that exists on all workers and the master and will be used for storing
# temporary spark/hadoop files. This can get big, so if you have a small root filesystem
# and an extra large drive mounted somewhere then you need to point this to somewhere on
# the large drive. On the other hand performance of this drive has big effect on overal speed,
# so SSD is a nice option here.
LOCAL_TMP_DIR=/mnt/tmp

# Find some working configurations below:
# TYPE=m1.large
# CORES=2
# USE_RAM_GB=3
# LOCAL_TMP_DIR=/mnt/tmp
#
# TYPE=m3.2xlarge
# CORES=8
# USE_RAM_GB=19
# LOCAL_TMP_DIR=/mnt/tmp

# The S3 directory to store graph data in without the s3:// prefix. It must use the same credentials
# as the user starting the cluster. Used as the backup location with the "s3copy" command.
# This needs to be in the same region as REGION. Or  you get charged by Amazon.
S3_DATAREPO=lynx-bnw-data/${USER}-cluster

# Spark installation to use for this cluster.
SPARK_VERSION=$(cat ${KITE_BASE}/conf/SPARK_VERSION)
