[[emr-file]]
### The EMR specifications file

This file contains various configurations used when launching LynxKite on Amazon Elastic
MapReduce (EMR).

Specify the name of the cluster.
```
CLUSTER_NAME=${USER}-cluster
```

Set the number of nodes in the cluster.
```
NUM_INSTANCES=3
```

Set the number of executors running in the cluster.
```
NUM_EXECUTORS=3
```

Specify the type of the instance to create.
```
TYPE=m3.2xlarge
```

Specify the id of the SSH key that you want to use to connect to the cluster.
```
SSH_ID=lynx-cli
```

Specify the private key file for the ID above.
```
SSH_KEY=${HOME}/.ssh/lynx-cli.pem
```

Specify in which region the cluster should run.
```
REGION=us-east-1
```

The configurations below are determined by the instance type above, however it is still required
to fill them. See the EMR
http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/TaskConfiguration_H2.html[task configuration]
documentation for memory limits and the EC2 https://aws.amazon.com/ec2/instance-types/[instance types]
documentation for number of cores.
```
CORES=8
# YARN limit minus overhead minus 1GB so that the application master fits on one machine.
USE_RAM_GB=18
```

The local temp directory is a local path that exists on all workers and the master and will
be used for storing temporary Spark/Hadoop files. This directory can potentially use a lot of
space, so if you have a small root filesystem and an extra large drive mounted somewhere then you
need to point this to somewhere on the large drive. On the other hand performance of this drive has
a significant effect on overall speed, so using an SSD is a nice option here.
```
LOCAL_TMP_DIR=/mnt/tmp
```

Another possible working configuration:
```
# TYPE=m1.large
# CORES=2
# USE_RAM_GB=3
# LOCAL_TMP_DIR=/mnt/tmp
```

Specify the S3 directory to store graph data in without the `s3://` prefix. It must use the
same credentials as the user starting the cluster. Used as the backup location with the
`s3copy` command. This needs to be in the same region as `REGION`. Or you get charged by Amazon.
```
S3_DATAREPO=lynx-bnw-data/${USER}-cluster
```

Extra parameters passed to the Amazon `aws emr create-cluster` command. You can configure
for example logging and Amazon EC2 debugging here.
```
CREATE_CLUSTER_EXTRA_PARAMS="--log-uri s3n://${S3_DATAREPO}/emr-logs/ --enable-debugging"
```

Specify additional EC2 attributes here. For example for deployment in a VPC private subnet, you'll
need to set SubnetId and AdditionalMasterSecurityGroups. E.g.:
`CREATE_CLUSTER_EXTRA_EC2_ATTRS='"SubnetId": "subnet-XXXX","AdditionalMasterSecurityGroups":["sg-YYYY"]'`
```
CREATE_CLUSTER_EXTRA_EC2_ATTRS=""
```

By default, emr.sh installs Spark by downloading an official version from cloudfront.net
directly to the master machine. This may be undesired in a Virtual Private Cluster setup,
where the master has no Internet access. In such cases, setting the below flag to "local"
tells emr.sh to upload the local Spark installation instead.

```
# DEPLOY_SPARK_FROM=local
```

Provides a part of the name for the `KITE_INSTANCE` variable that identifies the instance. E.g.,
leaving it at the default `emr` could result in such name: `emr-3-m3.2xlarge-8cores-18g`.
(The `KITE_INSTANCE` variable is assembled like this:
`${KITE_INSTANCE_BASE_NAME}-${NUM_INSTANCES}-${TYPE}-${CORES}cores-${USE_RAM_GB}g`)


```
KITE_INSTANCE_BASE_NAME=emr
```
