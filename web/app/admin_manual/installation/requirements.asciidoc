## Requirements

### Java version

You need Java 7 or higher on the system.

### Write permission

You need write permission to the directory configured as `KITE_DATA_DIR`. On HDFS a home directory
is also required for the user that starts LynxKite. Example commands to create these directories:

- `sudo -u hdfs hadoop fs -mkdir hdfs://$NAMENODE:8020/kite_data`
- `sudo -u hdfs hadoop fs -mkdir hdfs://$NAMENODE:8020/user/$USER`
- `sudo -u hdfs hadoop fs -chown $USER hdfs://$NAMENODE:8020/kite_data`
- `sudo -u hdfs hadoop fs -chown $USER hdfs://$NAMENODE:8020/user/$USER`

### Port collision

By default LynxKite runs on port 2200. If this is used by another process, move LynxKite to a
different port (by changing the `KITE_HTTP_PORT` setting in `.kiterc`).

[[yarn-memory-limit]]
### YARN memory limit

Set the executor memory (`EXECUTOR_MEMORY`) lower than the YARN NodeManager memory limit defined
with the `yarn.nodemanager.resource.memory-mb` and `yarn.scheduler.maximum-allocation-mb` settings
in the YARN configurations.

### Spark JVM overhead

By default Spark does not allocate enough memory overhead on top of the heap size for the JVM
itself. Set `spark.yarn.executor.memoryOverhead 4000` in `$SPARK_HOME/conf/spark-defaults.conf`.
Create `$SPARK_HOME/conf/spark-defaults.conf` from `$SPARK_HOME/conf/spark-defaults.conf.template`
if it does not exist.

