# Set to the directory containing your spark installation
export SPARK_HOME=$HOME/spark-${SPARK_VERSION}

# Specifies what cluster we use. Options are:
#  local - for single machine installs
#  yarn-client - for using yarn (hadoop v2). Please also set YARN_* settings below.
#  spark://master-name:master-port - for standalone spark clusters
export SPARK_MASTER=local

# The directory where Kite stores metadata about projects. Must be on the local file system.
# Do not forget to set up backups!
export KITE_META_DIR=$HOME/kite/meta

# The data where graph data is stored. Should be on a distributed fs (hdsf, s3, etc) unless
# this is a single machine install.
export KITE_DATA_DIR=$HOME/kite/data

# The PID file for Kite servers.
export KITE_PID_FILE=$HOME/kite/pid

# The user registry file for Kite servers.
export KITE_USERS_FILE=$HOME/kite/users.txt

# Needed if you want to run against yarn.
# The directory with the YARN configuration.
# export YARN_CONF_DIR=/etc/hadoop/...
# Number of executors.
# export YARN_NUM_EXECUTORS=2

# Specify how much memory is available for Kite on a single worker machine.
# Ignored for single machine installs, see SPARK_DRIVER_MEMORY_MB for that case.
export EXECUTOR_MEMORY=1g

# Number of cores per executor Kite should use. (For a YARN deployment, use this instead of
# the YARN_CORES_PER_EXECUTOR option that was available in pre-1.2 versions.)
export NUM_CORES_PER_EXECUTOR=4

# Specify how much memory is available for Kite on the master machine in megabytes.
# For standalone single machine instances this also determines executor memory and
# EXECUTOR_MEMORY is ignored in that case.
export KITE_MASTER_MEMORY_MB=1024

# Port for the Kite HTTP server to listen on. Must be >=1000.
export KITE_HTTP_PORT=9000

# HTTP port for the watchdog. If this is set, the startup script will start a watchdog as well
# which will automatically restart the Kite server if it detects any problem.
# export KITE_WATCHDOG_PORT=9999

# A local path that exists on all workers and the master and will be used for storing
# temporary spark/hadoop files. This can get big, so if you have a small root filesystem
# and an extra large drive mounted somewhere then you need to point this to somewhere on
# the large drive. On the other hand performance of this drive has big effect on overal speed,
# so SSD is a nice option here.
export KITE_LOCAL_TMP=/tmp

# Options needed if you want to use authentication and https.

# Just uncomment the lines between the ==== lines for simple, fake certificate setup.
# ===========================================================
# export KITE_APPLICATION_SECRET=${KITE_RANDOM_SECRET}
#
# Port for the Kite HTTPS server to listen on. Must be >=1000.
# export KITE_HTTPS_PORT=9001
#
# Keystore file and passwd with the HTTPS keys. Just leave as is for fake HTTPS certificate.
# For a real HTTPS setup, see https://github.com/biggraph/biggraph/issues/1178
# export KITE_HTTPS_KEYSTORE=${KITE_DEPLOYMENT_CONFIG_DIR}/localhost.self-signed.cert
# export KITE_HTTPS_KEYSTORE_PWD=asdasd
# ===========================================================

# Only needed for Google Auth ask the R&D team for further instructions if you think you need this.
# export KITE_GOOGLE_CLIENT_SECRET='???'
